## ðŸ“š CSCI - Applied Natural Language Processing (A)

## ðŸ’¡ Some Reflections...
While machine learning models are powerful tools for text analysis, their interpretability and utility in social science remain areas of challenge. In computational social science, machine learning often serves as a variable extraction tool, how can we use this to enhance research ðŸ¤”

## ðŸŽ“ Final Group Project: Sarcasm Detection
For the capstone project, the focus was on sarcasm detection in text, exploring the complexities of language and the challenges of modeling sarcasm:
- **Dataset and Model**: Applied advanced machine learning techniques, experimenting with embeddings and complex neural network architectures.
- **Reflections**: This project highlighted the potential of NLP for understanding nuanced language and the limitations of machine learning in interpreting context-heavy expressions.

## Coursework Overview
### Homework 1: Sentiment Analysis with Classic Machine Learning Models
This assignment focused on developing a sentiment analysis classifier using Amazon review data. Key steps included:
- **Data Preparation**: Processed Amazon reviews by creating binary sentiment labels.
- **Data Cleaning and Preprocessing**: Applied steps such as text cleaning, stop word removal, and lemmatization.
- **Feature Extraction**: Extracted TF-IDF features from the reviews.
- **Model Training**: Trained multiple classifiers (Perceptron, SVM, Logistic Regression, Naive Bayes) and evaluated performance with accuracy, precision, recall, and F1-score metrics.

### Homework 2: Word Embeddings and Neural Networks
Building upon the sentiment analysis task, this assignment introduced Word2Vec embeddings:
- **Word Embedding Models**: Utilized pre-trained Word2Vec embeddings (Google News) and custom-trained embeddings on the dataset.
- **Simple Models and Neural Networks**: Applied embeddings in Perceptron, SVM, and feedforward neural networks, comparing performance across different feature types.
- **Convolutional Neural Networks**: Built a CNN model for sentiment classification, highlighting the effectiveness of deep learning in sentiment analysis tasks.

### Homework 3: Part-of-Speech Tagging with Hidden Markov Models
This assignment introduced sequence tagging using part-of-speech (POS) tagging:
- **Vocabulary Creation and Model Learning**: Developed vocabulary and trained an HMM model based on emission and transition probabilities.
- **Decoding Algorithms**: Implemented both Greedy and Viterbi decoding algorithms to predict POS tags and evaluated the modelâ€™s accuracy.

### Homework 4: Named Entity Recognition with Bidirectional LSTM
The final assignment focused on named entity recognition (NER) with deep learning methods:
- **BiLSTM Model**: Implemented a bidirectional LSTM network for NER, achieving baseline performance.
- **Using Pre-trained GloVe Embeddings**: Enhanced the BiLSTM model by initializing embeddings with GloVe vectors, improving precision, recall, and F1-score.
- **LSTM-CNN Hybrid**: Incorporated a CNN module to capture character-level information, further boosting model performance.



## ðŸ‘‹ Connect

Thank you for visiting my GitHub! Feel free to explore my repositories, contribute, or reach out if you have insights or feedback. Let's advance the field of AI-mediated communication and computational social science together!
